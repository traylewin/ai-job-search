# Technical Decisions

This document explains the key technical and functional decisions behind the Job Hunt Agent, and how they address the requirements in [PROBLEM.md](PROBLEM.md).

---

## 1. Architecture Overview

The app is a Next.js 16 web application deployed to Vercel. The AI agent is powered by Anthropic Claude (Sonnet 4.5) through the Vercel AI SDK, which provides a built-in agentic loop with streaming. Data is persisted in two external services: Pinecone (vector search) and InstantDB (structured data and conversations). Authentication uses Google OAuth.

This maps directly to the core requirement: "a conversational agent with an agentic loop" and a "working CLI or simple web UI."

---

## 2. Why Pinecone for Vector Search

**Problem:** The dataset includes 40+ HTML job postings, 40+ emails, a resume, and notes. Dumping all of this into every LLM prompt would blow past context limits and waste tokens.

**Decision:** Embed all data into Pinecone using three namespaces (`job-postings`, `emails`, `resume`) so the agent can search semantically and only pull in what's relevant.

- Embeddings are generated by Pinecone's own Inference API using `llama-text-embed-v2` (1024 dimensions). This avoids needing a separate OpenAI key just for embeddings.
- The agent calls `searchJobs` or `searchEmails` first to find relevant items by meaning (e.g., "distributed systems roles in SF"), then deep-reads specific results. This keeps token costs low and satisfies the "context management" requirement.
- Each namespace stores metadata (company, date, type) so results can be filtered without re-embedding.

---

## 3. Why InstantDB for Structured Data

**Problem:** The app needs to persist parsed job data, tracker entries, email records, conversation history, and user preferences — with real-time sync and no infrastructure to manage.

**Decision:** InstantDB is a hosted real-time database with a declarative schema, instant syncing to the React client, and zero server setup.

- Stores 10 entity types: `jobPostings`, `trackerEntries`, `emails`, `emailThreads`, `resumeData`, `preferencesData`, `conversations`, `chatMessages`, plus user and link tables.
- Conversation memory across sessions (a "should have" requirement) comes for free — messages are saved to InstantDB and restored on reload.
- InstantDB's `db.tx.entity[id].update()` acts as an upsert: if the record doesn't exist, it creates it; if it does, it merges. This simplifies the ingestion pipeline since we don't need separate create/update paths.
- All queries are scoped by `userId`, supporting multi-tenant usage from a single deployment.

---

## 4. How Data Ingestion Works

The ingestion pipeline runs via `POST /api/ingest` and follows this flow:

```
Raw files (HTML, JSON, CSV, TXT, MD)
    → Parsers (cheerio, papaparse, custom)
        → InstantDB (structured records)
        → Pinecone (vector embeddings)
```

### HTML Parsing: Text-First, Structure-Second

This is the most important parsing decision. The 40 job posting HTMLs come from different sources with wildly different DOM structures, broken tags, and noise. A strict field-extraction parser would fail on most of them.

Instead, the parser always does two things:

1. **Extract raw text** — strip scripts, styles, nav, and cookie banners, then grab all readable text. This always succeeds.
2. **Attempt structured extraction** — try to pull out company, title, location, salary, requirements, etc. using CSS selectors, heading heuristics, and `__NEXT_DATA__` JSON. This is best-effort.

Each posting gets a `parseConfidence` tag: `"full"`, `"partial"`, or `"text-only"`. The agent sees this and knows when to trust structured fields vs. when to fall back to reading the raw file.

### CSV Tracker: Preserving Ambiguity

The requirement says: "If the tracker says `status: ???` the agent shouldn't guess." Our CSV parser stores both `statusRaw` (the original value, verbatim) and `statusNormalized` (a canonical mapping like "applied", "offer", "unknown"). Values like "???" are preserved as-is — the agent reports them honestly rather than guessing.

### Email Classification

Emails are classified by type (rejection, offer, interview scheduling, recruiter outreach, spam, etc.) using heuristic rules — keyword matching on subjects, bodies, and sender addresses. This is simple, fast, and good enough for the dataset without needing a trained classifier.

### Load Status Tracking

Sample data load status is tracked in browser localStorage (not the database) to avoid re-ingesting data that's already been loaded. Each data type (resume, emails, jobs, notes, tracker) has a boolean flag. The ingest endpoint checks these flags and skips sources that are already loaded unless forced.

---

## 5. Tool Design

The requirement asks for "at least 4 distinct tools." We built 12, organized into three categories:

| Category | Tools | Purpose |
|----------|-------|---------|
| **Search** | `searchJobs`, `searchEmails` | Semantic search via Pinecone to find relevant items without reading everything |
| **Read** | `readJobPosting`, `readEmailThread`, `readResume`, `readPreferences`, `readRawFile` | Deep-read specific records from InstantDB or raw files |
| **Action** | `queryTracker`, `updateTracker`, `addJobToTracker`, `computeDates`, `draftEmail` | Query/modify tracker, do date math, compose emails |

### The readRawFile Feedback Loop

This is the most important tool design decision. When structured parsing fails (e.g., salary comes back as `null`), the agent isn't stuck. It can call `readRawFile` to inspect the original HTML and extract the information itself. This closes a critical feedback loop:

1. Agent calls `readJobPosting("acme")` — gets `salary: null`, `parseConfidence: "partial"`
2. Agent calls `readRawFile("acme_careers.html")` — reads the raw text
3. Agent finds "$120k–$140k" buried in a footer div and reports it

Without this, the agent would be blind to anything the parser missed.

### draftEmail as Structured Output

When the agent drafts an email, the `draftEmail` tool returns structured data (`to`, `subject`, `body`) rather than just text. The UI renders this as a rich card with a copy button. The chat suppresses any redundant text the LLM generates after the tool call, so the user sees the card without duplication.

### Multi-Tenant Safety

All tools receive the authenticated `userId` and scope their database queries accordingly. One user cannot access another user's data.

---

## 6. The Agent Loop

The Vercel AI SDK's `streamText` function provides the agentic loop with `stopWhen: stepCountIs(10)` — up to 10 observe-think-act cycles per query. Each cycle:

1. The model receives the conversation plus any tool results from previous steps
2. It decides which tool to call next (or to respond directly)
3. The SDK executes the tool and feeds the result back

This handles multi-step reasoning naturally. For example, "Prepare me for my Notion interview" triggers:

1. `queryTracker({ company: "Notion" })` — get application status
2. `readJobPosting({ company: "Notion" })` — get role details
3. `searchEmails({ company: "Notion" })` — find interview logistics
4. `readResume({ section: "experience" })` — match relevant experience
5. `readPreferences({ section: "interviewQuestions" })` — pull prepared questions
6. Synthesize everything into a prep brief

The system prompt explicitly instructs the agent to: never hallucinate (say "I don't know" when information is missing), use `readRawFile` when structured data is incomplete, and report ambiguous tracker statuses verbatim.

---

## 7. Tool Call Display in the Chat UI

Tool calls are visible in the chat as collapsible cards — each shows the tool name, a summary of the inputs, and (when expanded) the full input/output JSON. This satisfies the "visible reasoning" requirement: the user can see exactly what the agent searched for, read, and computed.

The `draftEmail` tool gets special treatment: instead of a generic collapsible card, it renders as a styled email card with To, Subject, and Body fields plus a one-click copy button.

Streaming is real-time — tool call cards appear as the agent works, so the user sees progress before the final answer.

---

## 8. Proactive Alerts

On every page load, the app calls `GET /api/alerts`, which scans InstantDB for time-sensitive items:

- **Stale applications**: Applied 2+ weeks ago with no email activity
- **Upcoming interviews**: Scheduled dates in the near future
- **Offer deadlines**: Expiring offers that need decisions
- **Overdue follow-ups**: Companies where waiting has gone on too long

Alerts are displayed as cards above the chat. "Draft follow-up" alerts are sorted first since they're the most actionable. Clicking an alert pre-fills the chat input with a relevant prompt (e.g., "Draft a follow-up email to the Figma recruiter"), so the user can act on it immediately.

This addresses the gold-tier bonus: "proactive alerts — on startup, the agent scans your data and surfaces time-sensitive items without being asked."

---

## 9. Authentication

Users sign in with Google OAuth via `@react-oauth/google`. The Google JWT provides their name, email, and profile picture. InstantDB handles session management via `db.auth.signInWithIdToken()`.

When a user creates a new resume for the first time, the app pre-fills the name and contact fields from their Google profile — a small UX detail that avoids a blank-page experience.

---

## 10. Deployment

The app deploys to Vercel via a `deploy.sh` script that:

- Syncs environment variables from `.env.local` using `printf` (not `echo`) to avoid trailing newlines that break API keys
- Runs a local build check before deploying
- Supports both preview and production deployments

The sample data files (`data/`) are bundled into the serverless function via `outputFileTracingIncludes` in `next.config.ts`. Without this, Vercel's file tracing doesn't detect the data directory since it's accessed through dynamic string paths rather than static imports.
